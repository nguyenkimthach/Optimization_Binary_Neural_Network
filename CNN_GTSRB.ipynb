{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenkimthach/Optimization_Binary_Neural_Network/blob/main/CNN_GTSRB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4rgDVXAwUfa"
      },
      "source": [
        "# BinaryNet on GTSRB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UkmLz6LwewN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGeLJO_dJcnW"
      },
      "outputs": [],
      "source": [
        "!pip install larq\n",
        "!pip install tensorflow==2.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkf5eqw_xPM1"
      },
      "outputs": [],
      "source": [
        "# Fundamental classes\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import larq as lq\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "#from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu2t8KVTxPM5"
      },
      "source": [
        "# 2. Loading Dataset (Traffic Signs Images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT3JWVFsxPM7"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Setting variables for later use\n",
        "data = []\n",
        "labels = []\n",
        "classes = 43\n",
        "cur_path = os.getcwd()\n",
        "\n",
        "# Retrieving the images and their labels\n",
        "for i in range(classes):\n",
        "    path = os.path.join('/content/drive/MyDrive/gtsrb-german-traffic-sig/','Train',str(i))\n",
        "    images = os.listdir(path)\n",
        "\n",
        "    for a in images:\n",
        "        try:\n",
        "            image = Image.open(path + '/'+ a)\n",
        "            image = image.resize((30,30))\n",
        "            image = np.array(image)\n",
        "            #sim = Image.fromarray(image)\n",
        "            data.append(image)\n",
        "            labels.append(i)\n",
        "        except:\n",
        "            print(\"Error loading image\")\n",
        "\n",
        "# Converting lists into numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-FaDeELxPM_"
      },
      "source": [
        "# 3. Data Splitting and conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miZtp0NBxPNB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrGPaJFBxPND"
      },
      "outputs": [],
      "source": [
        "# Checking data shape\n",
        "print(data.shape, labels.shape)\n",
        "\n",
        "# Splitting training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Displaying the shape after the split\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# Converting the labels into one hot encoding\n",
        "y_train = to_categorical(y_train, 43)\n",
        "y_test = to_categorical(y_test, 43)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g53DtDvyxPNG"
      },
      "source": [
        "# 4. Creating and Compiling the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Btk2bEpWA2k"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization, SeparableConv2D,Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
        ")\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# filters 32, size of filters (3,3)\n",
        "model.add(Conv2D(16, (3, 3), input_shape=X_train.shape[1:], padding='same'))\n",
        "model.add(BatchNormalization(axis=-1)) #BatchNormalization normalizes the matrix after it is been through a convolution layer so that the scale of each dimension remains the same\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(16, (3, 3)))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32,(3, 3)))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten()) # act as an input to the Dense layers.\n",
        "\n",
        "# Fully connected layer\n",
        "model.add(Dense(64))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(43))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('softmax')) # Softmax activation enables us to calculate the output based on the probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCX70nLLhr1b"
      },
      "outputs": [],
      "source": [
        "# Compilation of the model\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.compile(\n",
        "     tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "     loss=\"categorical_crossentropy\",\n",
        "     metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVD_h7XAxPNM"
      },
      "source": [
        "# 5. Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZliURXCoxPNN"
      },
      "outputs": [],
      "source": [
        "# Training the Model classification-96-cnn\n",
        "with tf.device('/GPU:0'):\n",
        "    epochs = 30\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        batch_size=32,\n",
        "        epochs=epochs,\n",
        "        validation_data=(X_test, y_test)\n",
        ")\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47tynCqoxPNQ"
      },
      "source": [
        "# 6. Visualizing the performance of the Model during Training Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50U57-EoxPNR"
      },
      "outputs": [],
      "source": [
        "# Plotting performance graphs\n",
        "#plt.figure(0)\n",
        "paras1 = history.history['accuracy']\n",
        "paras1.insert(0,0.8)\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "#plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CT5GqDhkeZry"
      },
      "outputs": [],
      "source": [
        "#plt.figure(1)\n",
        "paras = history.history['loss']\n",
        "paras.insert(0,1.2)\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "#plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LvwaKhtUdOo"
      },
      "outputs": [],
      "source": [
        "print(f\"Test accuracy {test_acc * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73K--81uxPNV"
      },
      "source": [
        "# 7. Loading Test Dataset and Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9LaEhFYxPNW"
      },
      "outputs": [],
      "source": [
        "# testing accuracy on test dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Importing the test dataset\n",
        "y_test = pd.read_csv('/content/drive/MyDrive/gtsrb-german-traffic-sig/Test.csv')\n",
        "\n",
        "labels = y_test[\"ClassId\"].values\n",
        "imgs = y_test[\"Path\"].values\n",
        "\n",
        "data=[]\n",
        "\n",
        "# Retreiving the images\n",
        "with tf.device('/GPU:0'):\n",
        "    for img in imgs:\n",
        "        image = Image.open('/content/drive/MyDrive/gtsrb-german-traffic-sig/'+img)\n",
        "        image = image.resize([30, 30])\n",
        "        data.append(np.array(image))\n",
        "\n",
        "X_test=np.array(data)\n",
        "\n",
        "with tf.device('/GPU:0'):\n",
        "    pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "#Accuracy with the test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels, pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwEnMfuhxPNY"
      },
      "source": [
        "# 8. Savinng the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ESOAz2XxPNa"
      },
      "outputs": [],
      "source": [
        "# Saving the Model\n",
        "model.save('traffic_classifier.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}