{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenkimthach/Optimization_Binary_Neural_Network/blob/main/Binarynet_CNPB_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgcSMM0aGsrg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "!ls /content/drive/MyDrive\n",
        "#dataset_path = '/content/drive/MyDrive/newdataset/'\n",
        "train_path='/content/newdataset/train'\n",
        "test_path='/content/newdataset/test'\n",
        "save1_path='/content/drive/MyDrive/my_model_dataset_BNNsmall_20k_200eb_163264285612_3classnew.h5'\n",
        "save_path='/content/drive/MyDrive/DATASET2/BinaryNet_CNPB.h5'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ol3hRV3YjHcF"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "# Chọn file kaggle.json tải về ở bước 2 để tải lên\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d kimthchnguyn/newdataset\n",
        "!unzip -uq \"/content/newdataset.zip\"\n",
        "#!kaggle datasets download -d kimthchnguyn/ccnp-newdataset\n",
        "#!unzip -uq \"/content/ccnp-newdataset.zip\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQIghoNZRCCD"
      },
      "outputs": [],
      "source": [
        "#!pip install numpy==1.19.5\n",
        "!pip uninstall tensorflow -y\n",
        "!pip install tensorflow==2.7.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOXlYQQr47Es"
      },
      "outputs": [],
      "source": [
        "!pip install pyyaml h5py\n",
        "!pip install larq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkf5eqw_xPM1",
        "outputId": "8a38a76d-bb2b-4adf-f79f-a2ab7bbeb405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0-rc0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import larq as lq\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "from sklearn import preprocessing\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "from keras.utils import np_utils\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZWDEKy0cjhK"
      },
      "outputs": [],
      "source": [
        "img_width, img_height = 100, 100\n",
        "numberOfLabels = 3\n",
        "img_thresh =90\n",
        "def convert_to_binary(img_grayscale, thresh=100):\n",
        "    thresh, img_binary = cv2.threshold(img_grayscale, thresh, maxval=255, type=cv2.THRESH_BINARY)\n",
        "    return img_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACkALhcCyFT9"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "imagePaths = list(paths.list_images(train_path))\n",
        "# loop over the image paths\n",
        "for imagePath in imagePaths:\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    image = cv2.imread(imagePath, 0)\n",
        "    image = convert_to_binary(image, thresh=img_thresh)\n",
        "    image = cv2.resize(image, (img_width, img_height))\n",
        "    image = cv2.bitwise_not(image)\n",
        "    # image = image/255.0\n",
        "    # fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
        "    #                 cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
        "    # print(image)\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "#print(labels)\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(labels)\n",
        "labels = le.transform(labels)\n",
        "#print (labels[1])\n",
        "#print (image[1])\n",
        "#print(labels)\n",
        "\n",
        "data = np.array(data)\n",
        "x_train = data.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "y_train = np_utils.to_categorical(labels, numberOfLabels)\n",
        "#######################################################################################################\n",
        "data2 = []\n",
        "labels2 = []\n",
        "\n",
        "imagePaths = list(paths.list_images(test_path))\n",
        "# loop over the image paths\n",
        "for imagePath in imagePaths:\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    image = cv2.imread(imagePath, 0)\n",
        "    image = convert_to_binary(image, thresh=img_thresh)\n",
        "    image = cv2.resize(image, (img_width, img_height))\n",
        "    image = cv2.bitwise_not(image)\n",
        "    # image = image/255.0\n",
        "    # fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
        "    #                 cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
        "    # print(image)\n",
        "    data2.append(image)\n",
        "    labels2.append(label)\n",
        "#print(labels)\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(labels2)\n",
        "labels = le.transform(labels2)\n",
        "#print(labels)\n",
        "\n",
        "data = np.array(data2)\n",
        "x_test = data.astype('float32')\n",
        "\n",
        "x_test /= 255\n",
        "y_test = np_utils.to_categorical(labels2, numberOfLabels)\n",
        "\n",
        "#print(y_train)\n",
        "#img_width, img_height = 64, 64\n",
        "\n",
        "#train_data_dir = 'data/train'\n",
        "#validation_data_dir = 'data/test'\n",
        "#nb_train_samples = 330\n",
        "#nb_validation_samples = 60\n",
        "\n",
        "print(x_train.shape )\n",
        "print(x_test.shape )\n",
        "print(y_train.shape )\n",
        "print(y_test.shape )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3iFcARKyd1u"
      },
      "outputs": [],
      "source": [
        "# All quantized layers except the first will use the same options\n",
        "kwargs = dict(input_quantizer=\"ste_sign\",\n",
        "              kernel_quantizer=\"ste_sign\",\n",
        "              kernel_constraint=\"weight_clip\",\n",
        "              use_bias=False)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # In the first layer we only quantize the weights and not the input\n",
        "    lq.layers.QuantConv2D(16, 3,\n",
        "                          kernel_quantizer=\"ste_sign\",\n",
        "                          kernel_constraint=\"weight_clip\",\n",
        "                          use_bias=False,\n",
        "                          input_shape=(img_width, img_height, 1)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    # lq.layers.QuantConv2D(16, 3, padding=\"same\", **kwargs),\n",
        "    # tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    # tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D(16, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D( 16, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D(32, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "\n",
        "    lq.layers.QuantConv2D(32, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    lq.layers.QuantDense(64, **kwargs),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantDense(numberOfLabels, **kwargs),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "    tf.keras.layers.Activation(\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9af5Q4Sjyd12",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOrGniIeyd14",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "trained_model = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=32,\n",
        "    epochs=30,\n",
        "    validation_data=(x_test, y_test),\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaPdBGAXpeeh"
      },
      "outputs": [],
      "source": [
        "#save mode\n",
        "model.save(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVIvuoa6958q"
      },
      "outputs": [],
      "source": [
        "i=0\n",
        "for layer in model.layers:\n",
        "    print(layer.name, layer)\n",
        "    print(model.layers[i].weights)\n",
        "    i+=1\n",
        "# print(model.layers[18].weights)\n",
        "# model.save_weights('/content/drive/MyDrive/modelsave_weights.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJczMWztyd16"
      },
      "outputs": [],
      "source": [
        "plt.plot(trained_model.history['accuracy'])\n",
        "#plt.plot(trained_model.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "print(np.max(trained_model.history['accuracy']))\n",
        "print(np.max(trained_model.history['val_accuracy']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8ASqh8oyd16"
      },
      "outputs": [],
      "source": [
        "plt.plot(trained_model.history['loss'])\n",
        "#plt.plot(trained_model.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "print(np.min(trained_model.history['loss']))\n",
        "print(np.min(trained_model.history['val_loss']))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}