{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenkimthach/Optimization_Binary_Neural_Network/blob/main/CNN_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOXlYQQr47Es"
      },
      "outputs": [],
      "source": [
        "!pip install pyyaml h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBGJBLWjVKh2"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dense\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import time\n",
        "\n",
        "from keras.layers import Dropout\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNOKNAmcVUc9"
      },
      "outputs": [],
      "source": [
        "# load minit data\n",
        "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
        "\n",
        "#printng shape of mnist train and test data\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76q0KvL6VtGi"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "CNN accepts a specific format when using tensorflow e.g.(batch, height, width, channels)\n",
        "As all the images are in grayscale, the number of channels is 1\n",
        "'''\n",
        "# reshape the data to four dimensions, due to the input of model\n",
        "# reshape to be [samples/batch][width][height][pixels/channels]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "print(X_train.shape )\n",
        "print(X_test.shape )\n",
        "\n",
        "'''\n",
        "rescaled the image data below so that each pixel lies in the interval [0, 1] instead of [0, 255].\n",
        "'''\n",
        "# Normalization\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9J62JL0V7Hi"
      },
      "outputs": [],
      "source": [
        "#one-hot encoding an integer is converted to an array which contains only\n",
        "#one ‘1’ and the rest elements are ‘0’.\n",
        "\n",
        "# one-hot\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "print(y_train.shape )\n",
        "print(y_test.shape )\n",
        "num_classes = y_test.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Btk2bEpWA2k"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# filters 32, size of filters (3,3)\n",
        "model.add(Conv2D(16, (3, 3), input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization(axis=-1)) #BatchNormalization normalizes the matrix after it is been through a convolution layer so that the scale of each dimension remains the same\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(16, (3, 3)))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32,(3, 3)))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten()) # act as an input to the Dense layers.\n",
        "\n",
        "# Fully connected layer\n",
        "model.add(Dense(64))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10))\n",
        "\n",
        "model.add(Activation('softmax')) # Softmax activation enables us to calculate the output based on the probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLs2FDwSWSlp"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "start_time = time.time()\n",
        "trained_model=model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=30,\n",
        "    validation_data=(X_test, y_test),\n",
        "    shuffle=True\n",
        ")\n",
        "print(\"execution time:  %s ms\" % ((time.time() - start_time)*1000))\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhRWT1zfW2s9"
      },
      "outputs": [],
      "source": [
        "for layer in model.layers:\n",
        "    print(layer.name, layer)\n",
        "#save mode\n",
        "model.save('my_nom1_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJczMWztyd16"
      },
      "outputs": [],
      "source": [
        "#epoch_draw = [0, 5, 10, 15, 20, 25, 30]\n",
        "#accuracy_draw = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
        "#plt.xticks( np.arange(7),epoch_draw )\n",
        "#plt.yticks([0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96,0.97,0.98,0.99, 1])\n",
        "plt.plot(trained_model.history['accuracy'])\n",
        "plt.plot(trained_model.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "print(np.max(trained_model.history['accuracy']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8ASqh8oyd16"
      },
      "outputs": [],
      "source": [
        "plt.plot(trained_model.history['loss'])\n",
        "plt.plot(trained_model.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "print(np.min(trained_model.history['loss']))\n",
        "print(np.min(trained_model.history['val_loss']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LvwaKhtUdOo"
      },
      "outputs": [],
      "source": [
        "print(f\"Test accuracy {test_acc * 100:.2f} %\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}